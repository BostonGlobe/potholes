---
title: "potholes"
author: "Gabriel Florit"
output:
  html_document:
    self_contained: false
---

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
library(stringr)
library(lubridate)
library(rgdal)
library(dplyr)
library(ggplot2)
library(scales)
library(ggmap)

# Read csv.
potholes <- read.csv('../potholes.csv', strip.white=T, stringsAsFactors=F, row.names = NULL) %>%
  mutate(DATE.CLOSED.R = mdy(CLOSED_DT))

BOSTON <- fortify(readOGR(dsn='downloaded', layer='BOSTON'))
```

The following analysis is not meant for public consumption, at least not at the moment.

A note on the format: each question is followed by the R code that generates the answer. This is also known as **reproducible research**, a practice that's slowly being adopted by newspapers (e.g. [538](https://github.com/fivethirtyeight/data), [The Upshot](https://github.com/theupshot)). From [wikipedia](http://en.wikipedia.org/wiki/Reproducibility#Reproducible_research): "The term reproducible research refers to the idea that the ultimate product of academic research is the paper along with the full computational environment used to produce the results in the paper such as the code, data, etc. that can be used to reproduce the results and create new work based on the research."

***
### We're going to ignore `BOGUS` at first. Unless mentioned, we'll be plotting all rows.
#### How many potholes were closed per year?
```{r, results='asis', fig.width=10, fig.height=6, warning=FALSE, message=FALSE}
data <- potholes %>%
  group_by(year(DATE.CLOSED.R)) %>%
  summarise(potholes = n())

knitr::kable(data)
```

***
#### What does this look like on a timeseries?
```{r, results='asis', fig.width=10, fig.height=6, warning=FALSE, message=FALSE}
data <- potholes %>%
  filter(!is.na(DATE.CLOSED.R)) %>%
  group_by(DATE.CLOSED.R) %>%
  tally() %>%
  mutate(
    YEAR = year(DATE.CLOSED.R),
    DAY = yday(DATE.CLOSED.R)
  )

ggplot(data, aes(DAY, n)) +
  geom_line() +
  facet_grid(YEAR ~ .) +
  ggtitle('Daily pothole closures by year') +
  xlab('Day of year') +
  ylab('Pothole closures per day')
```

***
#### What's the distribution of total daily closures?
```{r, results='asis', fig.width=10, fig.height=6, warning=FALSE, message=FALSE}
data <- potholes %>%
  filter(!is.na(DATE.CLOSED.R)) %>%
  group_by(DATE.CLOSED.R) %>%
  tally() %>%
  mutate(YEAR = year(DATE.CLOSED.R))

ggplot(data, aes(n)) +
  geom_histogram() +
  facet_grid(YEAR ~ .) +
  ggtitle('Distribution of daily pothole closures by year') +
  xlab('Pothole closures per day') +
  ylab('Frequency')
```

***
#### What areas saw the most number of yearly closures?
```{r, results='asis', fig.width=10, fig.height=16, warning=FALSE, message=FALSE, dev='jpeg'}

minClosures <- 15

data <- potholes %>%
  filter(
    LATITUDE!=42.3594, LONGITUDE!=-71.0587,
    LATITUDE!=42.3601, LONGITUDE!=-71.0579,
    !is.na(DATE.CLOSED.R),
    !is.na(LATITUDE),
    !is.na(LONGITUDE)
    ) %>%
  mutate(
    YEAR = year(DATE.CLOSED.R),
    DISTRICT2 = pwd_district == 2
  ) %>%
  group_by(YEAR, LATITUDE, LONGITUDE, DISTRICT2) %>%
  tally() %>%
  ungroup() %>%
  filter(n >= minClosures) %>%
  arrange(desc(n))

map <- get_map(location=c(min(BOSTON$long), min(BOSTON$lat), max(BOSTON$long), max(BOSTON$lat)), zoom=11)

ggmap(map) +
  geom_polygon(aes(x=long, y=lat, group=group), data=BOSTON, fill='grey', size=0.5, color='black', alpha=0) +
  geom_point(aes(x=LONGITUDE, y=LATITUDE, size=n, alpha=0.1, colour=DISTRICT2), data=data) +
  geom_point(shape=1, aes(x=LONGITUDE, y=LATITUDE, size=n), data=data) +
  scale_size_continuous(range = c(4,20)) +
  ggtitle(str_c('Areas with at least ', minClosures, ' yearly closures')) +
  facet_grid(YEAR ~ .)
```

***
#### Can we zoom in on District 2?
```{r, results='asis', fig.width=10, fig.height=16, warning=FALSE, message=FALSE, dev='jpeg'}

map <- get_map(location=c(-71.1153, 42.29), zoom=13)
  
ggmap(map) +
  geom_point(aes(x=LONGITUDE, y=LATITUDE, size=n, alpha=0.1, colour=DISTRICT2), data=data) +
  geom_point(shape=1, aes(x=LONGITUDE, y=LATITUDE, size=n), data=data) +
  scale_size_continuous(range = c(4,20)) +
  ggtitle(str_c('Areas with at least ', minClosures, ' yearly closures')) +
  facet_grid(YEAR ~ .)
```

***
#### What areas saw the most number of daily closures?
```{r, results='asis', fig.width=10, fig.height=16, warning=FALSE, message=FALSE, dev='jpeg'}

data <- potholes %>%
  filter(
    LATITUDE!=42.3594, LONGITUDE!=-71.0587,
    LATITUDE!=42.3601, LONGITUDE!=-71.0579,
    !is.na(DATE.CLOSED.R),
    !is.na(LATITUDE),
    !is.na(LONGITUDE)
    ) %>%
  mutate(DISTRICT2 = pwd_district == 2) %>%
  group_by(DATE.CLOSED.R, LATITUDE, LONGITUDE, DISTRICT2) %>%
  tally() %>%
  ungroup() %>%
  mutate(YEAR = year(DATE.CLOSED.R)) %>%
  filter(n >= minClosures) %>%
  arrange(desc(n))

map <- get_map(location=c(min(BOSTON$long), min(BOSTON$lat), max(BOSTON$long), max(BOSTON$lat)), zoom=11)

ggmap(map) +
  geom_polygon(aes(x=long, y=lat, group=group), data=BOSTON, fill='grey', size=0.5, color='black', alpha=0) +
  geom_point(aes(x=LONGITUDE, y=LATITUDE, size=n, alpha=0.1, colour=DISTRICT2), data=data) +
  geom_point(shape=1, aes(x=LONGITUDE, y=LATITUDE, size=n), data=data) +
  scale_size_continuous(range = c(4,20)) +
  ggtitle(str_c('Areas with at least ', minClosures, ' daily closures')) +
  facet_grid(YEAR ~ .)
```

***
#### Can we zoom in on District 2?
```{r, results='asis', fig.width=10, fig.height=16, warning=FALSE, message=FALSE, dev='jpeg'}

map <- get_map(location=c(-71.1153, 42.29), zoom=13)

ggmap(map) +
  geom_point(aes(x=LONGITUDE, y=LATITUDE, size=n, alpha=0.1, colour=DISTRICT2), data=data) +
  geom_point(shape=1, aes(x=LONGITUDE, y=LATITUDE, size=n), data=data) +
  scale_size_continuous(range = c(4,20)) +
  ggtitle(str_c('Areas with at least ', minClosures, ' daily closures')) +
  facet_grid(YEAR ~ .)
```

***
#### What areas got the highest daily closures, by year?
```{r, results='asis', fig.width=10, fig.height=6, warning=FALSE, message=FALSE}
top <- data %>%
  group_by(YEAR) %>%
  arrange(desc(n)) %>%
  slice(1) %>%
  rename(DAILY.CLOSURES=n)

knitr::kable(top)
```


***
#### What's the source for the cluster with highest daily closures in 2014?
```{r, results='asis', fig.width=10, fig.height=6, warning=FALSE, message=FALSE}
first <- data[1,]

data <- potholes %>%
  group_by(Source) %>%
  tally()

knitr::kable(data)
```

***
#### What's the distribution of daily pothole closures per area, by year?
```{r, results='asis', fig.width=10, fig.height=6, warning=FALSE, message=FALSE}
data <- potholes %>%
  filter(
    LATITUDE!=42.3594, LONGITUDE!=-71.0587,
    !is.na(DATE.CLOSED.R),
    !is.na(LATITUDE),
    !is.na(LONGITUDE)
    ) %>%
  group_by(DATE.CLOSED.R, LATITUDE, LONGITUDE) %>%
  tally() %>%
  ungroup() %>%
  arrange(desc(n)) %>%
  mutate(YEAR = year(DATE.CLOSED.R))

ggplot(data, aes(n)) +
  geom_histogram(binwidth=1) +
  facet_grid(YEAR ~ .) +
  ggtitle('Distribution of daily pothole closures per area by year') +
  xlab('Pothole closures per day') +
  ylab('Frequency')
```
This graph shows that when multiple potholes are closed in the same area on the same day, most of the time that number is still in the single digits.

***
#### How long does it take to fix a constituent-generated pothole?
```{r, results='asis', fig.width=10, fig.height=6, warning=FALSE, message=FALSE}

convertMinutesToDays <- function(x) {
  d <- floor(x/(60*24))
}

data <- potholes %>%
  filter(Source %in% c('Citizens Connect App', 'Constituent Call', 'Self Service')) %>%
  transmute(
    OPEN = mdy_hms(str_c(Date.Created, ' ', Time.Created)),
    CLOSED = mdy_hms(str_c(Date.Closed, ' ', Time.Closed)),
    YEAR = year(CLOSED)
  ) %>%
  mutate(INTERVAL = interval(OPEN, CLOSED)%/%minutes(1))

data %>%
  filter(INTERVAL <= 60*24*7) %>%
  ggplot(aes(INTERVAL)) +
  geom_histogram(binwidth=60) +
  scale_x_continuous(label=convertMinutesToDays,breaks=seq(0,60*24*7,60*24)) +
  ggtitle('Distribution of pothole closure times (duration = 7 days or less)') +
  xlab('Days') +
  ylab('Count')
```

How strange. Why the hump around multiples of 24 hours? Looks like potholes are most likely to be closed 24 hours after they are open, or 48 hours after they are open, etc. How odd.